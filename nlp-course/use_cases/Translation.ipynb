{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981b424f-7ab2-4d4c-b3e5-5c49eb6450cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52196765-27ef-45b6-8626-8f24380af6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for kde4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/kde4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"kde4\", lang1=\"en\", lang2=\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e4e50a-c814-4b44-bda5-3af92b525995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 189155\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 21018\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=.9, seed=20)\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15aeb867-323d-4d56-a8cf-5339b6059a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets[\"validation\"] = split_datasets.pop(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8905b62e-3eee-4889-81f1-b57c5b6df859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Default to expanded threads',\n",
       " 'fr': 'Par défaut, développer les fils de discussion'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][1][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7483dbf-f6c8-458b-bf5a-11535340f072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Par défaut pour étendre les threads'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "translator(\"Default to expand threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9879782-7596-4242-84e4-dc00091c2174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',\n",
       " 'fr': \"Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][172][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64629330-2fdc-4382-88d8-031ba4c67a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = None\n",
    "for el in split_datasets[\"train\"][\"translation\"]:\n",
    "    if \"email\" in el[\"en\"]:\n",
    "        found = el\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea42c30c-4175-4d13-aa47-47bf3a5942d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Sends the chart as an email attachment.',\n",
       " 'fr': 'Envoie le diagramme comme pièce jointe.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6554c94b-2af5-49eb-8ff1-53f7b77bbd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_languages(examples):\n",
    "    translations = examples[\"translation\"]\n",
    "    return {\"en\": [ example[\"en\"] for example in translations], \"fr\": [ example[\"fr\"] for example in translations]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de6a1e2-3257-4781-a665-ef337e6b5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = split_datasets.map(extract_languages, batched=True, remove_columns=[\"translation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0f45392-ed6c-4e63-98c5-c60bcb4226d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f835eb6-0a67-48b7-b9e2-9c30bd1c6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\n",
    "fr_sentence = split_datasets[\"train\"][1][\"translation\"][\"fr\"]\n",
    "\n",
    "inputs = tokenizer(en_sentence, text_target=fr_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "084d3f14-f9fa-479e-95bd-f97c7e24acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
    "    )\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be4b0b93-7b47-47fc-8127-120e99a209e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c58c1a-e3ab-484a-be2a-eb9f85f10591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a18977ec-0217-496e-99f9-60b95d5d24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45bbacd8-9ab8-4636-824a-f41f9ef8abb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7377f80-b64b-477d-a09b-767fbf7cf921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,\n",
       "           550,  7032,  5821,  7907, 12649,     0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1c7c396-1db5-462b-a01f-79342a7a6fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[47591,    12,  9842, 19634,     9,     0, 59513, 59513, 59513, 59513,\n",
       "         59513, 59513, 59513, 59513, 59513],\n",
       "        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,\n",
       "         28149,   139, 33712, 25218,     0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ddffb86-898a-40fe-ae4d-d1405716bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,\n",
       "         59513, 59513, 59513, 59513, 59513, 59513],\n",
       "        [59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,\n",
       "           817,   550,  7032,  5821,  7907, 12649]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"decoder_input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40a7adde-6841-4765-a741-344233a7a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]\n",
      "[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "354a6ea3-b398-4409-a20a-23f0c3934962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (2.4.2)\n",
      "Requirement already satisfied: portalocker in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: regex in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from sacrebleu) (2024.4.16)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from sacrebleu) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "540ebec2-9dda-441a-996f-2ee015084a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (2.19.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: packaging in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hippolyteleveque/Documents/learning_projects/ML/huggingface-tutorials/env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "350b8f0d-e1bb-4183-bf7f-597d713840dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6ad03ab-35df-4c8d-b8cd-13f490c898ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 46.750469682990165,\n",
       " 'counts': [11, 6, 4, 3],\n",
       " 'totals': [12, 11, 10, 9],\n",
       " 'precisions': [91.66666666666667,\n",
       "  54.54545454545455,\n",
       "  40.0,\n",
       "  33.333333333333336],\n",
       " 'bp': 0.9200444146293233,\n",
       " 'sys_len': 12,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ff1b417-baeb-4271-b83b-70cd7bf273b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d496e8f-e7cc-491c-9e06-27e4d98ad060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9aa532078842e3b030f6727bed71ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e999eccc-a0f1-46e0-8d96-c59602048965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"marian-finetuned-kde4-en-to-fr\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    #fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08cad596-4336-4274-bf07-d1c023f8f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7230e3af-b317-4c7f-a98f-28f40fff0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8b97464-3a77-449d-8146-a049e6426edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed2f8c39-b6fd-4236-9daa-ab8f7f38d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import DataLoader\n",
    "#\n",
    "#tokenized_datasets.set_format(\"torch\")\n",
    "#train_dataloader = DataLoader(\n",
    "#    tokenized_datasets[\"train\"],\n",
    "#    shuffle=True,\n",
    "#    collate_fn=data_collator,\n",
    "#    batch_size=8,\n",
    "#)\n",
    "#eval_dataloader = DataLoader(\n",
    "#    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6d0939e-4bd3-42d1-b453-515868227977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d7dcbcc-1152-4464-ac59-342754d67871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10ef5048-4dfc-4f5c-b037-bf4a7eac3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from accelerate import Accelerator\n",
    "#\n",
    "#accelerator = Accelerator()\n",
    "#model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "#    model, optimizer, train_dataloader, eval_dataloader\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0fba39d-5c09-4d6c-91d6-4800a916957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import get_scheduler\n",
    "#\n",
    "#num_train_epochs = 3\n",
    "#num_update_steps_per_epoch = len(train_dataloader)\n",
    "#num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "#\n",
    "#lr_scheduler = get_scheduler(\n",
    "#    \"linear\",\n",
    "#    optimizer=optimizer,\n",
    "#    num_warmup_steps=0,\n",
    "#    num_training_steps=num_training_steps,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e72f570d-476a-4ae6-8032-c24ed5534f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    return decoded_preds, decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7636715-76ed-4a1c-92ca-00abd414c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm.auto import tqdm\n",
    "#import torch\n",
    "#\n",
    "#progress_bar = tqdm(range(num_training_steps))\n",
    "#\n",
    "#for epoch in range(num_train_epochs):\n",
    "#    # Training\n",
    "#    model.train()\n",
    "#    for batch in train_dataloader:\n",
    "#        outputs = model(**batch)\n",
    "#        loss = outputs.loss\n",
    "#        accelerator.backward(loss)\n",
    "#\n",
    "#        optimizer.step()\n",
    "#        lr_scheduler.step()\n",
    "#        optimizer.zero_grad()\n",
    "#        progress_bar.update(1)\n",
    "#\n",
    "#    # Evaluation\n",
    "#    model.eval()\n",
    "#    for batch in tqdm(eval_dataloader):\n",
    "#        with torch.no_grad():\n",
    "#            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "#                batch[\"input_ids\"],\n",
    "#                attention_mask=batch[\"attention_mask\"],\n",
    "#                max_length=128,\n",
    "#            )\n",
    "#        labels = batch[\"labels\"]\n",
    "#\n",
    "#        # Necessary to pad predictions and labels for being gathered\n",
    "#        generated_tokens = accelerator.pad_across_processes(\n",
    "#            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "#        )\n",
    "#        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "#\n",
    "#        predictions_gathered = accelerator.gather(generated_tokens)\n",
    "#        labels_gathered = accelerator.gather(labels)\n",
    "#\n",
    "#        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "#        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "#\n",
    "#    results = metric.compute()\n",
    "#    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n",
    "#\n",
    "#    # Save and upload\n",
    "#    accelerator.wait_for_everyone()\n",
    "#    unwrapped_model = accelerator.unwrap_model(model)\n",
    "#    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "#    if accelerator.is_main_process:\n",
    "#        tokenizer.save_pretrained(output_dir)\n",
    "#        repo.push_to_hub(\n",
    "#            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e25da3-6087-479f-a940-df9c8d529ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HG",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
